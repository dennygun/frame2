<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>80th Anniversary Indonesia Independence</title>
<style>
  body {
    margin: 0;
    overflow: hidden;
    background: black;
  }
  video, canvas {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    object-fit: cover;
  }
  #frame {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    box-sizing: border-box;
    border: 10px solid red;
    border-image: linear-gradient(90deg, red 50%, white 50%);
    border-image-slice: 1;
    pointer-events: none;
    animation: shine 4s linear infinite;
  }
  @keyframes shine {
    0% { border-image-source: linear-gradient(90deg, red 50%, white 50%); }
    50% { border-image-source: linear-gradient(90deg, white 50%, red 50%); }
    100% { border-image-source: linear-gradient(90deg, red 50%, white 50%); }
  }
  #text {
    position: absolute;
    top: 20px;
    width: 100%;
    text-align: center;
    font-size: 2em;
    font-weight: bold;
    color: white;
    text-shadow: 2px 2px 5px black;
    pointer-events: none;
  }
</style>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
</head>
<body>
<video id="video" autoplay playsinline></video>
<canvas id="drawCanvas"></canvas>
<div id="frame"></div>
<div id="text">80th Anniversary Indonesia Independence</div>
<script>
const video = document.getElementById('video');
const canvas = document.getElementById('drawCanvas');
const ctx = canvas.getContext('2d');

let model, drawing = false, lastX, lastY;

async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({ video: true });
  video.srcObject = stream;
  return new Promise(resolve => { video.onloadedmetadata = resolve; });
}

async function main() {
  await setupCamera();
  model = await handpose.load();
  video.play();
  canvas.width = window.innerWidth;
  canvas.height = window.innerHeight;
  detectHands();
}

async function detectHands() {
  const predictions = await model.estimateHands(video);
  ctx.lineWidth = 3;
  ctx.strokeStyle = 'yellow';
  ctx.lineCap = 'round';

  if (predictions.length > 0) {
    const landmarks = predictions[0].landmarks;
    const [x1, y1] = landmarks[4];
    const [x2, y2] = landmarks[8];
    const dist = Math.hypot(x2 - x1, y2 - y1);

    if (dist < 40) {
      if (!drawing) {
        drawing = true;
        lastX = x2 / video.videoWidth * canvas.width;
        lastY = y2 / video.videoHeight * canvas.height;
      }
      ctx.beginPath();
      ctx.moveTo(lastX, lastY);
      ctx.lineTo(x2 / video.videoWidth * canvas.width, y2 / video.videoHeight * canvas.height);
      ctx.stroke();
      lastX = x2 / video.videoWidth * canvas.width;
      lastY = y2 / video.videoHeight * canvas.height;
    } else {
      drawing = false;
    }
  }
  requestAnimationFrame(detectHands);
}

main();
</script>
</body>
</html>
